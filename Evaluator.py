from tqdm.auto import tqdm
import torch
from pathlib import Path
import os
import numpy as np
from settings import AMR_SCRIPT

import subprocess
from utils.eval_utils import cd, save_predictions, amr_postprocessing


class AmrEvaluator:
    def __init__(self, tokenizer,
                 eval_gold_file: Path,
                 sent_path: Path,
                 pred_save_dir: Path,
                 model,
                 dataloader,
                 src_lang="en",
                 silent_amr_postprocessing=False):

        self.keep_output_every_n = 100
        self.tokenizer = tokenizer
        self.model = model
        self.dataloader = dataloader

        self.model.eval()
        self.eval_gold_file = eval_gold_file
        self.sent_path = sent_path
        self.pred_save_dir = pred_save_dir
        self.src_lang = src_lang
        self.silent_amr_postprocessing = silent_amr_postprocessing


    def gen_outputs(self, max_len):
        eval_predictions = []
        decoder_start_token_id = self.tokenizer.convert_tokens_to_ids(["amr"])[0]
        eval_losses = []
        bad_words_ids = None

        # if self.src_lang == "zh":
        #     print("source lang is chinese, applying bad word ids..")
        #     bad_words_ids = self.get_bad_words_ids()

        with torch.no_grad():
            for _, dev_input in enumerate(tqdm(self.dataloader)):
                dev_input = {k: v.to(self.model.device) for k, v in dev_input.items()}
                eval_outputs = self.model(**dev_input)
                loss = eval_outputs.loss
                eval_losses.append(loss.item())
                eval_generated = self.model.generate(input_ids=dev_input["input_ids"],
                                                     attention_mask=dev_input["attention_mask"],
                                                     # decoder_start_token_id=decoder_start_token_id,
                                                     forced_bos_token_id=decoder_start_token_id,
                                                     bad_words_ids=bad_words_ids,
                                                     num_beams=5,
                                                     max_new_tokens=max_len,
                                                     early_stopping=True,
                                                     # max_time=120, # 2 minutes
                                                     )
                tok_eval_predictions = self.tokenizer.batch_decode(eval_generated, skip_special_tokens=True)
                eval_predictions.extend(tok_eval_predictions)
        return eval_predictions, eval_losses


    @staticmethod
    def compute_smatch(pred_path, ref_path):
        """
        pred_path: path to amr prediction generated by file
        ref_path: path to gold file (required to compute smatch score)  ex: {}.txt.graph
        """
        reformatted = pred_path.parent / (pred_path.name + ".restore.final.form")
        computed_smatch = pred_path.parent / "f_score.txt"
        # sanity check
        assert ref_path.exists()

        with cd(AMR_SCRIPT):
            subprocess.check_call(
                ["python", "smatch/smatch.py", "-f", reformatted, ref_path, "-r", "5", "--significant", "3", "--smatch_save_to", computed_smatch])

        with open(computed_smatch, 'r') as f:
            smatch = float(f.read().strip())

        return smatch

    def run_eval(self, max_len, n_step=None, suffix=None):
        self.n_step = n_step
        eval_predictions, eval_losses = self.gen_outputs(max_len=max_len)

        eval_gold_file = self.eval_gold_file
        destination_file = (
                self.pred_save_dir / f"step_{self.n_step}" /
                (f"{self.src_lang}_{suffix}" if suffix is not None else self.src_lang) /
                "pred.txt.tf"
        )

        eval_pred_file = save_predictions(eval_predictions, destination_file)
        eval_loss = np.mean(eval_losses)
        sent_path = self.sent_path

        try:
            os.environ["TOKENIZERS_PARALLELISM"] = "false"
            amr_postprocessing(eval_pred_file, sent_path, silent=self.silent_amr_postprocessing)

            smatch = AmrEvaluator.compute_smatch(eval_pred_file, eval_gold_file)
            os.environ["TOKENIZERS_PARALLELISM"] = "true"

        except subprocess.CalledProcessError as err:
            print(err)
            smatch = 0

        return eval_loss, smatch

